{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudarshan-raveendranath/Skin-Lession-Detection/blob/Akalanka/skin_lesion_efficientnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "zcp0rrSrtVll",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcp0rrSrtVll",
        "outputId": "558b81ee-fead-4f18-b807-0fc7edf8d8f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6yluKL9nt_54",
      "metadata": {
        "id": "6yluKL9nt_54"
      },
      "outputs": [],
      "source": [
        "# Example: Unzip a file from Google Drive\n",
        "# Replace 'path/to/your/zipped_file.zip' with the actual path to your zip file in Google Drive\n",
        "# Replace 'path/to/destination_folder' with the desired destination folder\n",
        "# !unzip '/content/drive/MyDrive/archive.zip' -d '/content/drive/MyDrive/DL'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5a6315b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a6315b8",
        "outputId": "ba878ef9-aa3f-4927-e680-323917e3b740"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Environment & imports\n",
        "# If running in a fresh environment, you may need to install packages:\n",
        "# !pip install torch torchvision matplotlib scikit-learn tqdm timm -q\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "484b910d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "484b910d",
        "outputId": "f9abfa7b-1a96-4f37-d354-616b2a9f134b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes (13): ['Actinic keratoses', 'Basal cell carcinoma', 'Benign keratosis-like lesions', 'Chickenpox', 'Cowpox', 'Dermatofibroma', 'HFMD', 'Healthy', 'Measles', 'Melanoma', 'Monkeypox', 'Squamous cell carcinoma', 'Vascular lesions']\n",
            "Train size: 19022  Val size: 2373\n"
          ]
        }
      ],
      "source": [
        "# Paths (change these to your dataset locations)\n",
        "train_dir = \"/content/drive/MyDrive/DL/train\"\n",
        "val_dir   = \"/content/drive/MyDrive/DL/val\"\n",
        "\n",
        "# Data transforms and augmentation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
        "val_dataset   = datasets.ImageFolder(val_dir, transform=val_transforms)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "class_names = train_dataset.classes\n",
        "num_classes = len(class_names)\n",
        "print(\"Classes ({}):\".format(num_classes), class_names)\n",
        "print(\"Train size:\", len(train_dataset), \" Val size:\", len(val_dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "61712fbe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61712fbe",
        "outputId": "5a6d1a03-4b63-4c82-e8a9-8071e20a35ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts: [693, 2658, 2099, 900, 792, 191, 1932, 1368, 660, 3617, 3408, 502, 202]\n",
            "Class weights: tensor([27.4488,  7.1565,  9.0624, 21.1356, 24.0177, 99.5916,  9.8458, 13.9050,\n",
            "        28.8212,  5.2591,  5.5816, 37.8924, 94.1683])\n"
          ]
        }
      ],
      "source": [
        "# Compute class weights to address imbalance\n",
        "from collections import Counter\n",
        "counts = Counter([y for _, y in train_dataset.samples])\n",
        "counts = [counts[i] for i in range(len(class_names))]\n",
        "print(\"Class counts:\", counts)\n",
        "class_weights = torch.tensor([sum(counts)/c for c in counts], dtype=torch.float).to(device)\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "07339a8a",
      "metadata": {
        "id": "07339a8a"
      },
      "outputs": [],
      "source": [
        "# EfficientNet-B0 (torchvision if available)\n",
        "try:\n",
        "    model = models.efficientnet_b0(pretrained=True)\n",
        "    num_ftrs = model.classifier[1].in_features\n",
        "    model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
        "except Exception as e:\n",
        "    # If torchvision doesn't have efficientnet in your environment, use timm (uncomment install if needed)\n",
        "    # !pip install timm -q\n",
        "    import timm\n",
        "    model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=num_classes)\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "54a2005c",
      "metadata": {
        "id": "54a2005c"
      },
      "outputs": [],
      "source": [
        "# Optimizer, scheduler\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "# Optional scheduler\n",
        "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "scheduler = None\n",
        "num_epochs = 10  # change as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a7ddaa07",
      "metadata": {
        "id": "a7ddaa07"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler=None, num_epochs=10, model_name=\"model\"):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_f1 = 0.0\n",
        "\n",
        "    history = {\"train_loss\":[],\"val_loss\":[],\"train_acc\":[],\"val_acc\":[], \"val_f1\":[]}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch+1, num_epochs))\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in [\"train\",\"val\"]:\n",
        "            if phase == \"train\":\n",
        "                model.train()\n",
        "                loader = train_loader\n",
        "            else:\n",
        "                model.eval()\n",
        "                loader = val_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            y_true = []\n",
        "            y_pred = []\n",
        "\n",
        "            for inputs, labels in tqdm(loader):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == \"train\"):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == \"train\":\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data).item()\n",
        "                y_true.extend(labels.cpu().numpy().tolist())\n",
        "                y_pred.extend(preds.cpu().numpy().tolist())\n",
        "\n",
        "            epoch_loss = running_loss / (len(loader.dataset))\n",
        "            epoch_acc = running_corrects / (len(loader.dataset))\n",
        "            epoch_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "            print(\"{} Loss: {:.4f} Acc: {:.4f} F1: {:.4f}\".format(phase, epoch_loss, epoch_acc, epoch_f1))\n",
        "\n",
        "            if phase == \"train\":\n",
        "                history[\"train_loss\"].append(epoch_loss)\n",
        "                history[\"train_acc\"].append(epoch_acc)\n",
        "            else:\n",
        "                history[\"val_loss\"].append(epoch_loss)\n",
        "                history[\"val_acc\"].append(epoch_acc)\n",
        "                history[\"val_f1\"].append(epoch_f1)\n",
        "                # deep copy the model\n",
        "                if epoch_f1 > best_f1:\n",
        "                    best_f1 = epoch_f1\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                    torch.save(model.state_dict(), f\"{model_name}_best.pth\")\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        print(\"-\"*30)\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(\"Training complete in {:.0f}m {:.0f}s\".format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print(\"Best val F1: {:.4f}\".format(best_f1))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "402a6221",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "402a6221",
        "outputId": "d3386947-ef57-4d8b-831e-4ccf81cb756a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 60/595 [11:45<1:42:10, 11.46s/it]"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "model, history = train_model(model, criterion, optimizer, scheduler, num_epochs=num_epochs, model_name=\"EfficientNet-B0\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "559814e5",
      "metadata": {
        "id": "559814e5"
      },
      "outputs": [],
      "source": [
        "def plot_history(history, model_name=\"model\"):\n",
        "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
        "    plt.figure(figsize=(12,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(epochs, history[\"train_loss\"], label=\"train_loss\")\n",
        "    plt.plot(epochs, history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.title(f\"{model_name} Loss\")\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(epochs, history[\"train_acc\"], label=\"train_acc\")\n",
        "    plt.plot(epochs, history[\"val_acc\"], label=\"val_acc\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.legend(); plt.title(f\"{model_name} Accuracy\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf7b5ab9",
      "metadata": {
        "id": "cf7b5ab9"
      },
      "outputs": [],
      "source": [
        "plot_history(history, model_name=\"EfficientNet-B0\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58eae84f",
      "metadata": {
        "id": "58eae84f"
      },
      "outputs": [],
      "source": [
        "# Load best model checkpoint (if needed) and run final evaluation on validation set\n",
        "def evaluate_model(model):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            y_true.extend(labels.cpu().numpy().tolist())\n",
        "            y_pred.extend(preds.cpu().numpy().tolist())\n",
        "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"Confusion matrix:\\n\", cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b708a75",
      "metadata": {
        "id": "3b708a75"
      },
      "source": [
        "## Notes and next steps\n",
        "- Tune learning rates, batch size, augmentation.\n",
        "- Consider 5-fold cross validation for robustness.\n",
        "- Use mixed precision (torch.cuda.amp) to speed up training on large GPUs.\n",
        "- Save final models and record results in a comparison table."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}