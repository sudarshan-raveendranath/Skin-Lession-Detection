{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "760ec7f6",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "760ec7f6",
        "outputId": "4f4672e4-e969-42bd-e946-ea3b251b0741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision matplotlib scikit-learn tqdm timm -q"
      ],
      "metadata": {
        "id": "_5VOEahJVIse"
      },
      "id": "_5VOEahJVIse",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import copy\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHVJrV-AVUrX",
        "outputId": "22fbc655-5c01-4de6-8055-31247265d28d"
      },
      "id": "cHVJrV-AVUrX",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "train_dir = \"/content/drive/MyDrive/DL/train\"\n",
        "val_dir   = \"/content/drive/MyDrive/DL/val\"\n",
        "test_dir  = \"/content/drive/MyDrive/DL/test\"\n",
        "\n",
        "# Data transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Datasets\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
        "val_dataset   = datasets.ImageFolder(val_dir, transform=val_test_transforms)\n",
        "test_dataset  = datasets.ImageFolder(test_dir, transform=val_test_transforms)\n",
        "\n",
        "# OPTIONAL: If you want to exclude one class (like \"Melanocytic nevi\")\n",
        "exclude_class = \"Melanocytic nevi\"\n",
        "if exclude_class in train_dataset.class_to_idx:\n",
        "    exclude_idx = train_dataset.class_to_idx[exclude_class]\n",
        "    from torch.utils.data import Subset\n",
        "    train_indices = [i for i, (_, label) in enumerate(train_dataset.samples) if label != exclude_idx]\n",
        "    val_indices = [i for i, (_, label) in enumerate(val_dataset.samples) if label != exclude_idx]\n",
        "    test_indices = [i for i, (_, label) in enumerate(test_dataset.samples) if label != exclude_idx]\n",
        "    train_dataset = Subset(train_dataset, train_indices)\n",
        "    val_dataset = Subset(val_dataset, val_indices)\n",
        "    test_dataset = Subset(test_dataset, test_indices)\n",
        "    class_names = [cls for cls in datasets.ImageFolder(train_dir).classes if cls != exclude_class]\n",
        "else:\n",
        "    class_names = train_dataset.classes\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Class info\n",
        "num_classes = len(class_names)\n",
        "print(f\"Classes ({num_classes}):\", class_names)\n",
        "print(\"Train size:\", len(train_dataset))\n",
        "print(\"Val size:\", len(val_dataset))\n",
        "print(\"Test size:\", len(test_dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqIdHt6NVX22",
        "outputId": "c677221f-f31a-4546-c968-48dbc91c03f6"
      },
      "id": "lqIdHt6NVX22",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes (13): ['Actinic keratoses', 'Basal cell carcinoma', 'Benign keratosis-like lesions', 'Chickenpox', 'Cowpox', 'Dermatofibroma', 'HFMD', 'Healthy', 'Measles', 'Melanoma', 'Monkeypox', 'Squamous cell carcinoma', 'Vascular lesions']\n",
            "Train size: 19022\n",
            "Val size: 2373\n",
            "Test size: 2386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from collections import Counter\n",
        "\n",
        "# Determine the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- Get labels from the train dataset ---\n",
        "if isinstance(train_dataset, torch.utils.data.Subset):\n",
        "    # For Subset, use the original dataset and indices\n",
        "    labels = [train_dataset.dataset.samples[i][1] for i in train_dataset.indices]\n",
        "else:\n",
        "    labels = [y for _, y in train_dataset.samples]\n",
        "\n",
        "# Compute class counts\n",
        "counts = Counter(labels)\n",
        "counts_list = [counts[i] for i in range(len(class_names))]\n",
        "print(\"Class counts:\", counts_list)\n",
        "\n",
        "# Compute class weights (inverse frequency)\n",
        "class_weights = torch.tensor([sum(counts_list)/c for c in counts_list], dtype=torch.float).to(device)\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "# Define weighted CrossEntropyLoss\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0LBKdY8WFha",
        "outputId": "fdae8b4b-18e2-4e11-d052-ef4cf1246c46"
      },
      "id": "s0LBKdY8WFha",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts: [693, 2658, 2099, 900, 792, 191, 1932, 1368, 660, 3617, 3408, 502, 202]\n",
            "Class weights: tensor([27.4488,  7.1565,  9.0624, 21.1356, 24.0177, 99.5916,  9.8458, 13.9050,\n",
            "        28.8212,  5.2591,  5.5816, 37.8924, 94.1683], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load ResNet-50 with the latest API\n",
        "weights = ResNet50_Weights.DEFAULT  # or IMAGENET1K_V1\n",
        "model = resnet50(weights=weights)\n",
        "\n",
        "# Replace the final layer for your num_classes\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "# Move to device\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzjIixpMXOyX",
        "outputId": "56bfacfb-0b4d-47ef-85dc-7782f5e9dd12"
      },
      "id": "QzjIixpMXOyX",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 196MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "# Optimizer: Adam with weight decay\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "\n",
        "# Optional learning rate scheduler (uncomment if you want to use it)\n",
        "# StepLR: reduce LR by gamma every step_size epochs\n",
        "# scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "# Currently no scheduler\n",
        "scheduler = None\n",
        "\n",
        "# Number of training epochs\n",
        "num_epochs = 10  # start with 10; increase if model hasn't converged"
      ],
      "metadata": {
        "id": "mkCdhebjYF2y"
      },
      "id": "mkCdhebjYF2y",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import time, copy\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler=None, num_epochs=10, model_name=\"model\"):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_f1 = 0.0\n",
        "\n",
        "    history = {\"train_loss\":[],\"val_loss\":[],\"train_acc\":[],\"val_acc\":[], \"val_f1\":[]}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        for phase in [\"train\",\"val\"]:\n",
        "            if phase == \"train\":\n",
        "                model.train()\n",
        "                loader = train_loader\n",
        "            else:\n",
        "                model.eval()\n",
        "                loader = val_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            y_true = []\n",
        "            y_pred = []\n",
        "\n",
        "            for inputs, labels in tqdm(loader):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == \"train\"):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == \"train\":\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data).item()\n",
        "                y_true.extend(labels.cpu().numpy())\n",
        "                y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "            epoch_loss = running_loss / len(loader.dataset)\n",
        "            epoch_acc = running_corrects / len(loader.dataset)\n",
        "            epoch_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} F1: {epoch_f1:.4f}\")\n",
        "\n",
        "            if phase == \"train\":\n",
        "                history[\"train_loss\"].append(epoch_loss)\n",
        "                history[\"train_acc\"].append(epoch_acc)\n",
        "            else:\n",
        "                history[\"val_loss\"].append(epoch_loss)\n",
        "                history[\"val_acc\"].append(epoch_acc)\n",
        "                history[\"val_f1\"].append(epoch_f1)\n",
        "                if epoch_f1 > best_f1:\n",
        "                    best_f1 = epoch_f1\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                    torch.save(model.state_dict(), f\"{model_name}_best.pth\")\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        print(\"-\"*30)\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f\"Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
        "    print(f\"Best val F1: {best_f1:.4f}\")\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history\n"
      ],
      "metadata": {
        "id": "5LU7pNbcY3He"
      },
      "id": "5LU7pNbcY3He",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, history = train_model(\n",
        "    model,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    num_epochs=num_epochs,\n",
        "    model_name=\"ResNet50\"\n",
        ")"
      ],
      "metadata": {
        "id": "xaKynEr5ZveA",
        "outputId": "a98f2208-17b3-4096-91be-f722f43d7ef8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xaKynEr5ZveA",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▎    | 319/595 [21:43<17:51,  3.88s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NB4xXOq9Z3Lt"
      },
      "id": "NB4xXOq9Z3Lt",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}